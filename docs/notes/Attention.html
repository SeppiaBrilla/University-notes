<!DOCTYPE <!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <script src="../js/functions.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href="../css/style.css" rel="stylesheet">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.5.1/mermaid.min.js" integrity="sha512-gAfYc+bjXAmXUHDG1Dm8AiUWDz8PhByz2852OW/ZitnuM4gGZPD8oQhz57KR2WcDcoCvZInSH1HqbZwMpjHdeg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
        <title>Attention</title>
    </head>
    <body class="dark-theme-bg">
        <div id="Content" class="content">
            <header id="TitleDiv" class="dark-theme-color">
                <h1>Attention</h1>
            </header>
            <nav id="OptionDiv">
                <a href="../index.html"><i class="fas fa-home icon dark-theme-color"></i></a>
                <button onclick="BackFn()"><i class="fas fa-arrow-left icon dark-theme-color"></i></button>
                <button onclick="ThemeFn()"><i class="fas fa-adjust icon dark-theme-color"></i></button>
            </nav>
            <div class="main dark-theme-color">
                <p>It is among the most fundamental of cognitive functions, particularly in humans and other primates for whom vision is the dominant sense.
Selective visual attention describes the tendency of visual processing to be confined largely to stimuli that are relevant to behavior.</p>
<h3>Biased competition model of selective visual attention</h3>
<p>We can process only a small amount of information at any given time, therefore, our brain must select what stimuli consider and what stimuli avoid. Attended stimuli make demands on processing capacity, while unattended ones often do not.</p>
<p><img src="./Pasted_image_20231002180700.png" alt="Pasted image 20231002180700.png">
</p>
<h2>Types of visual selective attention</h2>
<ul>
<li><strong>Top-down vs. Bottom-up</strong> </li>
<li><strong>Space based vs. Object based</strong></li>
<li><strong>Covert vs. Overt orienting</strong></li>
</ul>
<h3>Top-down</h3>
<p>Selective processing due to an endogenously generated signal. Top-down attention can be engaged to select one object over another, as well as to follow a particular instructional set or general rule</p>
<h3>Bottom-up</h3>
<p>selective processing that is generated externally by the physical properties of stimuli. Exogenous attention allows novel or salient information to transiently interrupt goal-directed behavior.</p>
<p><img src="./Pasted_image_20231002181401.png" alt="Pasted image 20231002181401.png">
</p>
<p>Contrast can also influence the response of neurons. Two alternatives hypotheses to explain the effect of attention on the neuron response to a stimulus inside its RF:</p>
<ol>
<li>Response gain model: attention has a multiplicative effect on the neuronal response. The response is multiplied by a constant factor, and the effect of attention is maximum for the highest stimulus contrasts. The result is that the CRF function moves upward.</li>
<li>Contrast (sensitivity) gain model: attention increases sensitivity to contrast. The effect of attention is maximum in the area of the curve where the neuronal response is most dynamic (steep). The result is that the sigmoid curve shifts to the left</li>
</ol>
<p><img src="./Pasted_image_20231002183757.png" alt="Pasted image 20231002183757.png">
</p>
<h3>Attention alters visual cortical receptive fields</h3>
<p>Vision is limited by many factors including the visual system’s spatial resolution (or acuity), the ability to discriminate two nearby points in space. This shift in spatial attention results in enhanced visual processing, including enhanced spatial resolution, contrast sensitivity, and speed of information processing, at the attended location.</p>
<p><img src="./Pasted_image_20231002191442.png" alt="Pasted image 20231002191442.png">
</p>
<p>It is crucial to understand the way information is encoded in populations of neurons:</p>
<ol>
<li>If the noise in individual neurons is independent, averaging the responses of many
neurons will lead to a very accurate estimate of the mean, no matter how noisy the
individual neurons are.</li>
<li>If, however, there are positive correlations in the trial-to-trial fluctuations of the
responses of pairs of neurons, then the shared (or correlated) variability can never be
averaged out, leading to a more variable (and less accurate) estimate of the mean activity in
the population</li>
</ol>
<ul>
<li>Attention increased V4 neuron firing rates</li>
<li>Attention reduced the trial-to-trial variability of individual neurons</li>
<li>Attention decreased noise correlation, that is the correlation between the variability or fluctuation of the responses of pairs of neurons, in each trial. It represents how much variability (or noise) is shared by a group of neurons.</li>
<li>For pairs of neurons in the same hemisphere, correlation was lower when the stimulus in the neurons’ RF was attended (black line) than when it was unattended (gray line). Pairs of neurons in opposite hemispheres (dashed lines) had correlations that were close to zero.</li>
<li>Noise correlation was highest for neurons with similar tuning (positive signal correlation) and lowest for neurons with opposite tuning (negative signal correlation). However, the effect of attention on noise correlation did not depend on the degree of tuning similarity (signal correlation) between cells.</li>
</ul>
<p>Neurons at the earliest stages of visual processing are tuned to simple visual features such
as luminance and color contrast, edge orientation, direction of motion, or stereo disparity.
Processing becomes increasingly more specialized with the progression from low-level to
high level visual areas, such that higher-level visual areas include neurons that respond only
to terminations, corners or junctions, shape-from-shading cues, illusory contours, or views
of specific real-world objects.</p>
<p><img src="./Pasted_image_20231002194314.png" alt="Pasted image 20231002194314.png">
</p>
<h3>Overt vs. Convert attention</h3>
<p>Gaze direction and the attention focus are often spatially aligned (i.e., overt attention).
Nonetheless, it is also possible to attend to objects of interest in the visual scene without
shifting our gaze (i.e., covert attention).
Covert attention is the form of spatial attention most often studied in vision neuroscience.</p>

            </div>
        </div>
    </body>
</html>
