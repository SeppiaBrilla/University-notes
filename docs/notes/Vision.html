<!DOCTYPE <!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <script src="../js/functions.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href="../css/style.css" rel="stylesheet">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.5.1/mermaid.min.js" integrity="sha512-gAfYc+bjXAmXUHDG1Dm8AiUWDz8PhByz2852OW/ZitnuM4gGZPD8oQhz57KR2WcDcoCvZInSH1HqbZwMpjHdeg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
        <title>Vision</title>
    </head>
    <body class="dark-theme-bg">
        <div id="Content" class="content">
            <header id="TitleDiv" class="dark-theme-color">
                <h1>Vision</h1>
            </header>
            <nav id="OptionDiv">
                <a href="../index.html"><i class="fas fa-home icon dark-theme-color"></i></a>
                <button onclick="BackFn()"><i class="fas fa-arrow-left icon dark-theme-color"></i></button>
                <button onclick="ThemeFn()"><i class="fas fa-adjust icon dark-theme-color"></i></button>
            </nav>
            <div class="main dark-theme-color">
                <p>What does it mean, to see? 
Vision is the process of discovering what is present in the world, and where it is.
Vision is a process that produces from images of the external world a description that is useful to the viewer and not cluttered with irrelevant information.
Vision is often incorrectly compared to the operation of a camera. A camera simply reproduces point-by-point the light intensities in one plane of the visual<br>field. The visual system, in contrast, does something fundamentally different. It<br>interprets the scene and parses it into distinct components, separating foreground<br>from background.</p>
<p>Traditionally, a visual scene is analyzed at three levels: low, intermediate and high.</p>
<ul>
<li>At the lowest level, visual attributes such as local contrast, orientation, color, depth and motion are processed.</li>
<li>At an intermediate level, Low-level features are used to parse the visual scene. Local orientation is integrated into global contours; local visual features are assembled into surfaces, objects are segregated from background, surface shape is identified from depth, shading and kinematic cues.</li>
<li>The highest level concerns object recognition.</li>
</ul>
<p>Visual processing is mediated by the retino-geniculo-striate pathway
<img src="./Pasted_image_20230920191513.png" alt="Pasted image 20230920191513.png">
</p>
<h3>Visual field</h3>
<p>Is the area that can be seen as you fixate your eyes on a central point</p>
<h3>Eyes split</h3>
<p>The retina of each eye can be divided into two part: left and right.
The left hemiretinas (temporal of the left eye, and nasal of the right eye) see the right (opposite) visual hemifield.
The right hemiretinas (nasal of the left eye, and temporal of the right eye) see the left (opposite) visual hemifield.
Because the temporal hemiretina of one eye sees the same visual hemifield as the nasal hemiretina of the other eye, partial decussation of the optic nerve fibers at the chasm<br>ensures that all information related to each hemifield is processed in the visual cortex of the contralateral hemisphere.
<img src="./Pasted_image_20230505185340.png" alt="Pasted image 20230505185340.png">
</p>
<p>In primates, LGN is a layered structure consisting of six layers, of which two Magnocellular layers (layers 1 and 2), and four Parvocellular layers (layers 3 to<br>6). Each layer receives input from either the ipsilateral eye (temporal hemiretina, layers 2, 3, 5) or the contralateral eye (nasal hemiretina, layers 1, 4, 6)</p>
<h3>Receptive field</h3>
<p>Visual neurons respond to stimuli in only a limited region of space. This region of space is referred to as that cell’s receptive field (RF).</p>
<h3>Eccentricity</h3>
<p>The receptive fields of the retinal ganglion cells that monitor portions of the fovea subtend about 0.1° (equal to 6 min of arc), while those in the visual periphery reach up to 1° of visual angle or more.</p>
<h3>Cortical magnification</h3>
<p>The amount of cortical area devoted to each degree of the visual field, known as the<br>magnification factor, varies with eccentricity.</p>
<h1>Area V1</h1>
<h2>Types of receptors</h2>
<p>Humans, like most vertebrates, possess two types of photoreceptors, rods and cones, differing in shape, function, connectivity and distribution in the retina.</p>
<ul>
<li>Rods (100 million) are mainly for night (or scotopic) vision. They can signal the absorption of 1 single photon; their response saturated in daylight, and they cease to respond to variation of intensity</li>
<li>Cones (5 million) are only for daytime (or photopic) vision. They are much less sensitive to light, make no contribution to night vision, but have higher spatial and temporal resolution (their response is considerably faster than that of rods)</li>
</ul>
<p><img src="./Pasted_image_20230920194551.png" alt="Pasted image 20230920194551.png">
</p>
<p>RGCs respond only weakly to uniform stimulation. RGC mainly emphasize the contrasts of brightness.</p>
<p><img src="./Pasted_image_20230505191104.png" alt="Pasted image 20230505191104.png">
</p>
<p>RGCs have concentric circular receptive fields and falls into two categories:</p>
<ul>
<li>ON-center: respond to light in the center of the receptive field</li>
<li>OFF-center: respond to dark in the center of the receptive field</li>
</ul>
<p><img src="./Pasted_image_20230920195514.png" alt="Pasted image 20230920195514.png">
</p>
<p><img src="./Pasted_image_20230920200218.png" alt="Pasted image 20230920200218.png">
</p>
<p>Neurons in area V1 are classically divided into two types: simple and complex. Each neuron responds better to a different orientation.
Simple cells respond well to sinusoidal gratings (Gabor patches) of specific spatial frequencies and phases. Complex cells have rectangular big receptive fields, respond to specific orientation and linear stimuli, the position of the stimuli is non-critical, the movement of the stimuli is very effective but only in selective directions.
Complex cells are less selective for the position of the stimulus in the receptive field
The receptive field has no defined ON and OFF regions and responds similarly to light (on a
dark background) or dark (on a light background) stimuli in all positions of the receptive
field. They are activated as a linear oriented stimulus crosses their receptive fields in one
direction.</p>
<p><img src="./Pasted_image_20230920201352.png" alt="Pasted image 20230920201352.png">
</p>
<p>According to the hierarchical model (Hubel and Wiesel, 1962), simple cell receptive fields
are constructed from the convergence of geniculate inputs with receptive fields aligned in
the visual space. In turn, complex receptive fields arise from the convergence of simple cells with similar orientation preferences.</p>
<p>V1 neurons are also selective for:</p>
<ul>
<li>orientation</li>
<li>spatial frequency</li>
<li>direction</li>
<li>temporal frequency</li>
<li>disparity</li>
<li>color</li>
</ul>
<p><img src="./Pasted_image_20230920201845.png" alt="Pasted image 20230920201845.png">
</p>
<p>Neurons with the same orientation preference are grouped together in columns. Each column has a few hundreds of cells each. Moving from a column to the next one, the orientation change of 10–15 degrees. A set of columns that corresponds to a complete sequence of orientation is called hypercolumn. </p>
<h3>Ocular dominance columns</h3>
<p><img src="./Pasted_image_20230920225601.png" alt="Pasted image 20230920225601.png">
</p>
<p>Both the orientation and ocular dominance columns have blobs of neurons that are poorly selective for orientation but good for color detection.</p>
<h1>Area V2</h1>
<p>In this area, thick and thin dark strips separated by pale stripes are evident with cytochrome oxidase labeling.</p>
<ul>
<li>The thick stripes contain neurons selective for direction of movement and binocualr disparity</li>
<li>The thin stripes contain cells specialized for color </li>
<li>The pale stripes contain orientation selective neurons</li>
</ul>
<p><img src="./Pasted_image_20230920230522.png" alt="Pasted image 20230920230522.png">
</p>
<p>The dorsal and ventral pathways are highly interconnected so that information is shared.</p>
<h2>3D vision</h2>
<p>It is based on:</p>
<ul>
<li>monocular elements:<ul>
<li>familiarity with the object</li>
<li>interposition</li>
<li>linear perspective</li>
<li>size of objects</li>
<li>distribution of shadow and lighting</li>
<li>parallax movement</li>
</ul>
</li>
<li>stereoscopic elements</li>
</ul>
<h3>binocular disparity</h3>
<p><img src="./Pasted_image_20230920231115.png" alt="Pasted image 20230920231115.png">
</p>
<p><img src="./Pasted_image_20230920231207.png" alt="Pasted image 20230920231207.png">
</p>
<h3>Visual motion</h3>
<p><img src="./Pasted_image_20230920231320.png" alt="Pasted image 20230920231320.png">
</p>
<p><img src="./Pasted_image_20230920231445.png" alt="Pasted image 20230920231445.png">
</p>
<h2>Areas</h2>
<p><img src="./Pasted_image_20230920233520.png" alt="Pasted image 20230920233520.png">
</p>
<p>The neurons that respond to the different parts of an object are not randomly arranged in
the IT area.
Neurons that respond to same elements are grouped in a cortical column, analogous to the
orientation columns found in V1. Contiguous columns encode elements related to each
other.</p>
<p>Studies by Tanaka have shown that IT neurons that seem selective for a specific object,
actually respond to a part or component of the object, and not to the object as a whole.
These parts of objects that activate neurons can be found in a variety of different stimuli,
and constitute a sort of visual alphabet for the recognition of objects.</p>
<p><img src="./Pasted_image_20230920234107.png" alt="Pasted image 20230920234107.png">
</p>

            </div>
        </div>
    </body>
</html>
