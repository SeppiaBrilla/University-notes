<!DOCTYPE <!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <script src="../js/functions.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href="../css/style.css" rel="stylesheet">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.5.1/mermaid.min.js" integrity="sha512-gAfYc+bjXAmXUHDG1Dm8AiUWDz8PhByz2852OW/ZitnuM4gGZPD8oQhz57KR2WcDcoCvZInSH1HqbZwMpjHdeg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
        <title>Model based clustering</title>
    </head>
    <body class="dark-theme-bg">
        <div id="Content" class="content">
            <header id="TitleDiv" class="dark-theme-color">
                <h1>Model based clustering</h1>
            </header>
            <nav id="OptionDiv">
                <a href="../index.html"><i class="fas fa-home icon dark-theme-color"></i></a>
                <button onclick="BackFn()"><i class="fas fa-arrow-left icon dark-theme-color"></i></button>
                <button onclick="ThemeFn()"><i class="fas fa-adjust icon dark-theme-color"></i></button>
            </nav>
            <div class="main dark-theme-color">
                <p>Model based are <a href="./__University_University-notes_Machine_learning_Clustering_Clustering.html">Clustering</a>
 techniques that use statistics in order to build a model that captures the meaning of the data.
The main technique uses the mixture model that view the data as a mixture of different probability distribution summed together.
As a base model, usually, a multivariate <a href="./__University_University-notes_Statistical_and_Mathematical_Methods_for_Artificial_Intelligence_Statistics_Gaussian_(normal)_distribution.html">Gaussian (normal) distribution</a>
 is used and the estimator is usually made with <a href="./__University_University-notes_Statistical_and_Mathematical_Methods_for_Artificial_Intelligence_Statistics_Maximum_likelihood_estimation.html">Maximum likelihood estimation</a>
. An important assumption on the data is that every variable must be independent of the others, like in <a href="./__University_University-notes_Machine_learning_Classification_Naive_Bayes_classifier.html">Naive Bayes classifier</a>
.</p>
<h1>Gaussian mixture (EM)</h1>
<p>Gaussian mixture, or Expectation maximization, is an algorithm used to find the best distribution mixture to describe the data.</p>
<h3>Pseudocode</h3>
<pre><code class="language-python">def EM():
    parameters = get_initia_model()
    while(get_parameters_change(parameters) &gt;= trashold):
        expectation = [compute_probability_belonging(parameters, x) for x in dataset]
        parameters = maximizeLikelihood(parameters, x)

    return parameters
</code></pre>

            </div>
        </div>
    </body>
</html>
